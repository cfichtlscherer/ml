{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "#from tensorflow import keras\n",
    "\n",
    "from matplotlib import patches\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras import Sequential                                                                      \n",
    "from keras.models import Model                                                                    \n",
    "from keras.callbacks import EarlyStopping                                                         \n",
    "from keras.layers import Dense, Input, Convolution2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout, Softmax, Activation\n",
    "from keras import optimizers                                                                      \n",
    "from tensorflow.keras.models import load_model                                                    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "\n",
    "import json\n",
    "import PIL as PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/home/cpf/Desktop/GTSRB/Final_Training/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_numpy_reshape(path, x_size = 50, y_size = 50):\n",
    "    \"\"\" Input: path to image, x_size, y_size of the output\n",
    "        Output: numpy array\"\"\"\n",
    "    \n",
    "    big_enough = False\n",
    "        \n",
    "    image_data = PIL.Image.open(path)\n",
    "    xs, ys, cs = np.asarray(image_data).shape\n",
    "    if (xs > x_size + 15) and (y_size+15 > 35):\n",
    "        big_enough = True\n",
    "        image_data.thumbnail((x_size+10, y_size+10), Image.ANTIALIAS)\n",
    "        image_data = ImageOps.fit(image_data, (x_size, y_size), Image.ANTIALIAS)\n",
    "        image_data = np.asarray(image_data)\n",
    "    \n",
    "    return big_enough, image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "number_elements = 1300\n",
    "\n",
    "image_array = np.zeros((number_elements, 50, 50, 3))\n",
    "label_array = np.zeros(number_elements) - 1\n",
    "\n",
    "t_counter = 0\n",
    "\n",
    "#for ending in tqdm(['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008']):\n",
    "for ending in tqdm(['00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008']):\n",
    "    data_files = os.listdir(path_data + '/' + ending)\n",
    "    counter = 0\n",
    "    for file in data_files:\n",
    "        if ('.ppm' in file) and (counter < 250) and (t_counter < number_elements):\n",
    "            path = path_data + '/' + ending + '/' + file\n",
    "            big_enough, image_data = image_numpy_reshape(path)\n",
    "            if big_enough == True:\n",
    "                image_array[t_counter] = image_data/255\n",
    "                label_array[t_counter] = float(ending[-1:]) - 1 \n",
    "                counter += 1\n",
    "                t_counter += 1\n",
    "                if t_counter == number_elements - 1:\n",
    "                    print(\"all_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 0\n",
      "0 250\n",
      "1 250\n",
      "2 164\n",
      "3 232\n",
      "4 148\n",
      "5 32\n",
      "6 147\n",
      "7 77\n",
      "8 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1,9):\n",
    "    print(i, np.count_nonzero(label_array == i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle and Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(image_array))\n",
    "image_array_shuffled, label_array_shuffled = image_array[p], label_array[p]\n",
    "\n",
    "split = 1300\n",
    "\n",
    "training_images = image_array_shuffled[:split]\n",
    "training_labels = label_array_shuffled[:split]\n",
    "\n",
    "test_images = image_array_shuffled[split:]\n",
    "test_labels = label_array_shuffled[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 17.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# we test on a set with 300 images:\n",
    "path_data_test = '/home/cpf/Desktop/GTSRB-Online-Test-sort'\n",
    "\n",
    "number_elements = 250\n",
    "\n",
    "image_array_test = np.zeros((number_elements, 50, 50, 3))\n",
    "label_array_test = np.zeros(number_elements) - 1 - 1\n",
    "\n",
    "t_counter = 0\n",
    "\n",
    "#for ending in tqdm(['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008']):\n",
    "for ending in tqdm(['00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008']):\n",
    "    data_files_test = os.listdir(path_data_test + '/' + ending)\n",
    "    counter = 0\n",
    "    for file in data_files_test:\n",
    "        if ('.ppm' in file) and (counter < 40) and (t_counter < number_elements):\n",
    "            path = path_data_test + '/' + ending + '/' + file\n",
    "            big_enough, image_data = image_numpy_reshape(path)\n",
    "            if big_enough == True:\n",
    "                image_array_test[t_counter] = image_data/255\n",
    "                label_array_test[t_counter] = float(ending[-1:]) - 1\n",
    "                counter += 1\n",
    "                t_counter += 1\n",
    "                if t_counter == number_elements - 1:\n",
    "                    print(\"all_in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cpf/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()                                                 \n",
    "model.add(Convolution2D(32, (3, 3),activation='relu', input_shape=(50,50,3)))   \n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#model.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "model.add(Convolution2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "#model.add(Convolution2D(15, (3,3),activation='relu'))\n",
    "#model.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten()),   \n",
    "#model.add(Dense(10, activation='relu'))     \n",
    "model.add(Dense(8, activation='softmax'))     \n",
    "model.build()                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 12552     \n",
      "=================================================================\n",
      "Total params: 22,696\n",
      "Trainable params: 22,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cpf/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1170 samples, validate on 130 samples\n",
      "Epoch 1/100\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 2.0157 - accuracy: 0.3983 - val_loss: 1.9835 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.9666 - accuracy: 0.2650 - val_loss: 1.9160 - val_accuracy: 0.6846\n",
      "Epoch 3/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.9267 - accuracy: 0.3402 - val_loss: 1.8604 - val_accuracy: 0.4846\n",
      "Epoch 4/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.8341 - accuracy: 0.2333 - val_loss: 1.7795 - val_accuracy: 0.2154\n",
      "Epoch 5/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.7126 - accuracy: 0.1957 - val_loss: 1.7018 - val_accuracy: 0.1769\n",
      "Epoch 6/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.6297 - accuracy: 0.2085 - val_loss: 1.5974 - val_accuracy: 0.2385\n",
      "Epoch 7/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.5623 - accuracy: 0.2103 - val_loss: 1.5431 - val_accuracy: 0.2385\n",
      "Epoch 8/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.4956 - accuracy: 0.1991 - val_loss: 1.5120 - val_accuracy: 0.2385\n",
      "Epoch 9/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.4611 - accuracy: 0.1983 - val_loss: 1.4734 - val_accuracy: 0.2385\n",
      "Epoch 10/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.4318 - accuracy: 0.1991 - val_loss: 1.4599 - val_accuracy: 0.2615\n",
      "Epoch 11/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.4112 - accuracy: 0.1932 - val_loss: 1.4334 - val_accuracy: 0.2385\n",
      "Epoch 12/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3965 - accuracy: 0.1932 - val_loss: 1.4232 - val_accuracy: 0.2385\n",
      "Epoch 13/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3898 - accuracy: 0.1940 - val_loss: 1.4122 - val_accuracy: 0.2385\n",
      "Epoch 14/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3787 - accuracy: 0.1940 - val_loss: 1.4077 - val_accuracy: 0.2462\n",
      "Epoch 15/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3754 - accuracy: 0.1949 - val_loss: 1.3980 - val_accuracy: 0.2538\n",
      "Epoch 16/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3718 - accuracy: 0.1940 - val_loss: 1.3978 - val_accuracy: 0.2308\n",
      "Epoch 17/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3700 - accuracy: 0.1966 - val_loss: 1.3941 - val_accuracy: 0.2462\n",
      "Epoch 18/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3688 - accuracy: 0.1923 - val_loss: 1.3930 - val_accuracy: 0.2538\n",
      "Epoch 19/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3656 - accuracy: 0.1940 - val_loss: 1.3914 - val_accuracy: 0.2462\n",
      "Epoch 20/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3643 - accuracy: 0.1983 - val_loss: 1.3933 - val_accuracy: 0.2538\n",
      "Epoch 21/100\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 1.3637 - accuracy: 0.1983 - val_loss: 1.3909 - val_accuracy: 0.2692\n",
      "Epoch 22/100\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 1.3629 - accuracy: 0.1983 - val_loss: 1.3895 - val_accuracy: 0.2538\n",
      "Epoch 23/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3634 - accuracy: 0.1940 - val_loss: 1.3986 - val_accuracy: 0.2462\n",
      "Epoch 24/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3619 - accuracy: 0.1957 - val_loss: 1.3851 - val_accuracy: 0.2692\n",
      "Epoch 25/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3601 - accuracy: 0.2017 - val_loss: 1.3836 - val_accuracy: 0.2538\n",
      "Epoch 26/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3595 - accuracy: 0.2034 - val_loss: 1.3854 - val_accuracy: 0.2538\n",
      "Epoch 27/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3594 - accuracy: 0.1957 - val_loss: 1.3858 - val_accuracy: 0.2615\n",
      "Epoch 28/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3592 - accuracy: 0.2017 - val_loss: 1.3846 - val_accuracy: 0.2538\n",
      "Epoch 29/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3582 - accuracy: 0.1991 - val_loss: 1.3843 - val_accuracy: 0.2538\n",
      "Epoch 30/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3578 - accuracy: 0.2009 - val_loss: 1.3826 - val_accuracy: 0.2615\n",
      "Epoch 31/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3576 - accuracy: 0.2000 - val_loss: 1.3819 - val_accuracy: 0.2538\n",
      "Epoch 32/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3574 - accuracy: 0.2051 - val_loss: 1.3825 - val_accuracy: 0.2538\n",
      "Epoch 33/100\n",
      "1170/1170 [==============================] - 2s 2ms/step - loss: 1.3572 - accuracy: 0.2077 - val_loss: 1.3856 - val_accuracy: 0.2462\n",
      "Epoch 34/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3573 - accuracy: 0.2017 - val_loss: 1.3815 - val_accuracy: 0.2538\n",
      "Epoch 35/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3567 - accuracy: 0.2009 - val_loss: 1.3821 - val_accuracy: 0.2615\n",
      "Epoch 36/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3566 - accuracy: 0.2111 - val_loss: 1.3821 - val_accuracy: 0.2538\n",
      "Epoch 37/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3565 - accuracy: 0.2077 - val_loss: 1.3822 - val_accuracy: 0.2769\n",
      "Epoch 38/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3561 - accuracy: 0.2051 - val_loss: 1.3821 - val_accuracy: 0.2538\n",
      "Epoch 39/100\n",
      "1170/1170 [==============================] - 2s 1ms/step - loss: 1.3559 - accuracy: 0.2060 - val_loss: 1.3818 - val_accuracy: 0.2692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa8762c56d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=100,\n",
    "                                            validation_split=0.1, \n",
    "                                            shuffle=True, \n",
    "                                            verbose=1,\n",
    "                                            callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "correct = np.argmax(predictions, axis=1) == label_array_test \n",
    "accuracy = np.sum(correct) / correct.size\n",
    "print('\\nTest accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('class_models/classification_model_' + str(accuracy) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 151\n",
    "plt.imshow(image_array_test[image_number])\n",
    "plt.show()\n",
    "print(predictions[image_number])\n",
    "print(label_array_test[image_number])\n",
    "\n",
    "plt.plot(range(9), predictions[image_number], \"o\")\n",
    "plt.plot(label_array_test[image_number], [0], \"o\", color=\"red\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
